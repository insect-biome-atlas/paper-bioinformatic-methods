import pandas as pd

def read_params(f):
    df = pd.read_csv(f, sep="\t", index_col=0)
    df.index = [str(x) for x in df.index]
    return df.to_dict(orient="index")


# Removing 'Raphidioptera' and 'Zoraptera' from the list here because no clusters had >84% identity
orders = ['Diptera', 'Hymenoptera', 'Coleoptera', 'Psocodea', 
          'Lepidoptera', 'Strepsiptera', 'Mecoptera', 'Trichoptera', 
          'Thysanoptera', 'Symphypleona', 'Odonata', 'Entomobryomorpha', 
          'Hemiptera', 'Plecoptera', 'Ephemeroptera', 'Poduromorpha', 
          'Megaloptera', 'Neuroptera', 'Siphonaptera', 'Blattodea', 
          'Zygentoma', 'Orthoptera', 'Dermaptera', 'Psocoptera', 
          'Archaeognatha', 'Neelipleona', 
          'Diplura']

echo_params_dict = read_params("runs/echo_run_params.tsv")
evo_params_dict = read_params("runs/evo_run_params.tsv")
abundance_params_dict = read_params("runs/abundance_run_params.tsv")
ee_params_dict = read_params("runs/ee_run_params.tsv")
eee_params_dict = read_params("runs/eee_run_params.tsv")
eeea_params_dict = read_params("runs/eeea_run_params.tsv")

wildcard_constraints:
    order="|".join(orders),
    i="|".join(echo_params_dict.keys()),
    evo_run="|".join(evo_params_dict.keys()),
    abundance_run="|".join(abundance_params_dict.keys()),
    ee_run="|".join(ee_params_dict.keys()),
    eee_run="|".join(eee_params_dict.keys()),
    eeea_run="|".join(eeea_params_dict.keys()),
    method="echo|evo|abundance|ee|eee|eeea"

localrules:
    aggregate_method,
    add_hexapoda,
    all

rule all:
    input:
        expand("results/{method}_res.tsv", method=["echo", "evo", "abundance", "ee", "eee", "eeea"])

rule run_echo_filter:
    output:
        discarded="raw_results/{order}/echo_run{i}_discarded_otus.tsv",
        res_file="results/{order}/echo_res_{i}.tsv",
    input:
        counts="data/{order}_counts.tsv",
        taxonomy="data/{order}_taxonomy.tsv",
        matchlist="data/{order}_evodistlist.tsv",
        #hex_tax = "data/Hexapoda_taxonomy.tsv",
        params="runs/echo_run_params.tsv",
        se_family="evaluation_data/se_fauna_family.tsv",
        finbol_tax="evaluation_data/finbol_taxonomy.tsv",
    log:
        "logs/{order}/echo_run_{i}.log"
    resources:
        mem_mb=lambda wildcards: 4000 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 12000,
        runtime=lambda wildcards: 240 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 60,
        slurm_partition="shared",
        slurm_account="naiss2024-5-207"
    params:
        min_match=lambda wildcards: echo_params_dict[wildcards.i]["min_match"],
        min_overlap=lambda wildcards: echo_params_dict[wildcards.i]["min_overlap"],
        read_ratio_type=lambda wildcards: echo_params_dict[wildcards.i]["read_ratio_type"],
        max_read_ratio=lambda wildcards: echo_params_dict[wildcards.i]["max_read_ratio"],
        require_corr=lambda wildcards: echo_params_dict[wildcards.i]["require_corr"],
        echo_filter=workflow.source_path("code/echo_filter.R"),
        eval_fun=workflow.source_path("code/evaluate_fxns.R"),
        get_data=workflow.source_path("code/get_data_fxns.R")
    script:
        "scripts/run_echo_filter.R"

rule run_ee_filter:
    output:
        discarded="raw_results/{order}/ee_run{ee_run}_discarded_otus.tsv",
        res_file="results/{order}/ee_res_{ee_run}.tsv",
    input:
        discarded=lambda wildcards: expand("raw_results/{{order}}/echo_run{echo_run}_discarded_otus.tsv",
            echo_run = str(ee_params_dict[wildcards.ee_run]["echo_run"])),
        counts="data/{order}_counts.tsv",
        taxonomy="data/{order}_taxonomy.tsv",
        evodistlist="data/{order}_evodistlist.tsv",
        params="runs/ee_run_params.tsv",
        se_family="evaluation_data/se_fauna_family.tsv",
        finbol_tax="evaluation_data/finbol_taxonomy.tsv",
    log:
        "logs/{order}/ee_run_{ee_run}.log"
    params:
        evo_filter=workflow.source_path("code/evo_filter.R"),
        eval_fun=workflow.source_path("code/evaluate_fxns.R"),
        get_data=workflow.source_path("code/get_data_fxns.R"),
        dist_type=lambda wildcards: ee_params_dict[wildcards.ee_run]["dist_type"],
        dist_threshold=lambda wildcards: ee_params_dict[wildcards.ee_run]["dist_threshold"],
        require_overlap=lambda wildcards: ee_params_dict[wildcards.ee_run]["require_overlap"],
    resources:
        mem_mb=lambda wildcards: 4000 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 12000,
        runtime=lambda wildcards: 240 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 60,
        slurm_partition="shared",
        slurm_account="naiss2024-5-207"
    script:
        "scripts/run_ee_filter.R"

rule eee_filter:
    output:
        discarded="raw_results/{order}/eee_run{eee_run}_discarded_otus.tsv",
        res_file="results/{order}/eee_res_{eee_run}.tsv"
    input:
        discarded=lambda wildcards: expand("raw_results/{{order}}/ee_run{ee_run}_discarded_otus.tsv",
            ee_run = str(eee_params_dict[wildcards.eee_run]["ee_run"])),
        counts="data/{order}_counts.tsv",
        taxonomy="data/{order}_taxonomy.tsv",
        evodistlist="data/{order}_evodistlist.tsv",
        params="runs/eee_run_params.tsv",
        se_family="evaluation_data/se_fauna_family.tsv",
        finbol_tax="evaluation_data/finbol_taxonomy.tsv",
    log:
        "logs/{order}/eee_run_{eee_run}.log"
    params:
        evo_filter=workflow.source_path("code/evo_filter.R"),
        eval_fun=workflow.source_path("code/evaluate_fxns.R"),
        get_data=workflow.source_path("code/get_data_fxns.R"),
        require_overlap=lambda wildcards: eee_params_dict[wildcards.eee_run]["require_overlap"],
        dist_type=lambda wildcards: eee_params_dict[wildcards.eee_run]["dist_type"],
        dist_threshold=lambda wildcards: eee_params_dict[wildcards.eee_run]["dist_threshold"],
    resources:
        mem_mb=lambda wildcards: 4000 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 12000,
        runtime=lambda wildcards: 240 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 60,
        slurm_partition="shared",
        slurm_account="naiss2024-5-207"
    script:
        "scripts/run_eee_filter.R"

def get_counts(wildcards):
    count_type = eeea_params_dict[wildcards.eeea_run]["count_type"]
    if count_type == "raw":
        return f"data/{wildcards.order}_counts.tsv"
    elif count_type == "tot_proportional":
        return f"data/{wildcards.order}_tot_prop_counts.tsv"
    elif count_type == "sample_proportional":
        return f"data/{wildcards.order}_sample_prop_counts.tsv"
    elif count_type == "calibrated":
        return f"data/{wildcards.order}_cal_counts.tsv"

rule run_eeea_filter:
    output:
        discarded="raw_results/{order}/eeea_run{eeea_run}_discarded_otus.tsv",
        res_file="results/{order}/eeea_res_{eeea_run}.tsv",
    input:
        discarded=lambda wildcards: expand("raw_results/{{order}}/eee_run{eee_run}_discarded_otus.tsv",
            eee_run = str(eeea_params_dict[wildcards.eeea_run]["eee_run"])),
        counts=get_counts,
        taxonomy="data/{order}_taxonomy.tsv",
        params="runs/eeea_run_params.tsv",
        se_family="evaluation_data/se_fauna_family.tsv",
        finbol_tax="evaluation_data/finbol_taxonomy.tsv",
    log:
        "logs/{order}/eeea_run_{eeea_run}.log"
    params:
        abundance_filter=workflow.source_path("code/abundance_filter.R"),
        eval_fun=workflow.source_path("code/evaluate_fxns.R"),
        get_data=workflow.source_path("code/get_data_fxns.R"),
        cutoff=lambda wildcards: eeea_params_dict[wildcards.eeea_run]["cutoff"],
        cutoff_type=lambda wildcards: eeea_params_dict[wildcards.eeea_run]["cutoff_type"],
    resources:
        mem_mb=lambda wildcards: 4000 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 12000,
        runtime=lambda wildcards: 60 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 30,
        slurm_partition="shared",
        slurm_account="naiss2024-5-207"
    script:
        "scripts/run_eeea_filter.R"

rule evo_filter:
    output:
        discarded="raw_results/{order}/evo_run{evo_run}_discarded_otus.tsv",
        res_file="results/{order}/evo_res_{evo_run}.tsv",
    input:
        counts="data/{order}_counts.tsv",
        taxonomy="data/{order}_taxonomy.tsv",
        evodistlist="data/{order}_evodistlist.tsv",
        params="runs/evo_run_params.tsv",
        se_family="evaluation_data/se_fauna_family.tsv",
        finbol_tax="evaluation_data/finbol_taxonomy.tsv",
    log:
        "logs/{order}/evo_run_{evo_run}.log"
    params:
        evo_filter=workflow.source_path("code/evo_filter.R"),
        eval_fun=workflow.source_path("code/evaluate_fxns.R"),
        get_data=workflow.source_path("code/get_data_fxns.R"),
        dist_type=lambda wildcards: evo_params_dict[wildcards.evo_run]["dist_type"],
        dist_threshold=lambda wildcards: evo_params_dict[wildcards.evo_run]["dist_threshold"],
        require_overlap=lambda wildcards: evo_params_dict[wildcards.evo_run]["require_overlap"],
    resources:
        mem_mb=lambda wildcards: 4000 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 12000,
        runtime=lambda wildcards: 240 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 60,
        slurm_partition="shared",
        slurm_account="naiss2024-5-207"
    script:
        "scripts/run_evo_filter.R"

def get_abundance_filter_counts(wildcards):
    count_type = abundance_params_dict[wildcards.abundance_run]["count_type"]
    if count_type == "raw":
        return f"data/{wildcards.order}_counts.tsv"
    elif count_type == "tot_proportional":
        return f"data/{wildcards.order}_tot_prop_counts.tsv"
    elif count_type == "sample_proportional":
        return f"data/{wildcards.order}_sample_prop_counts.tsv"
    elif count_type == "calibrated":
        return f"data/{wildcards.order}_cal_counts.tsv"

rule abundance_filter:
    output:
        discarded="raw_results/{order}/abundance_run{abundance_run}_discarded_otus.tsv",
        res_file="results/{order}/abundance_res_{abundance_run}.tsv",
    input:
        counts=get_abundance_filter_counts,
        taxonomy="data/{order}_taxonomy.tsv",
        params="runs/abundance_run_params.tsv",
        se_family="evaluation_data/se_fauna_family.tsv",
        finbol_tax="evaluation_data/finbol_taxonomy.tsv",
    log:
        "logs/{order}/abundance_run_{abundance_run}.log"
    params:
        abundance_filter=workflow.source_path("code/abundance_filter.R"),
        eval_fun=workflow.source_path("code/evaluate_fxns.R"),
        get_data=workflow.source_path("code/get_data_fxns.R"),
        cutoff=lambda wildcards: abundance_params_dict[wildcards.abundance_run]["cutoff"],
        cutoff_type=lambda wildcards: abundance_params_dict[wildcards.abundance_run]["cutoff_type"],
    resources:
        mem_mb=lambda wildcards: 4000 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 12000,
        runtime=lambda wildcards: 60 if wildcards.order in ["Diptera", "Hymenoptera","Coleoptera","Hemiptera","Lepidoptera", "Orthoptera"] else 30,
        slurm_partition="shared",
        slurm_account="naiss2024-5-207"
    script:
        "scripts/run_abundance_filter.R"

rule aggregate_order:
    output:
        touch("results/{order}/done")
    input:
        echo = expand("results/{{order}}/echo_res_{i}.tsv", 
            i=list(echo_params_dict.keys())),
        evo = expand("results/{{order}}/evo_res_{evo_run}.tsv",
            evo_run=list(evo_params_dict.keys())),
        abundance = expand("results/{{order}}/abundance_res_{abundance_run}.tsv",
            abundance_run=list(abundance_params_dict.keys())),
        ee = expand("results/{{order}}/ee_res_{ee_run}.tsv", 
            ee_run=list(ee_params_dict.keys())),
        eee = expand("results/{{order}}/eee_res_{eee_run}.tsv", 
            eee_run=list(eee_params_dict.keys())),
        eeea = expand("results/{{order}}/eeea_res_{eeea_run}.tsv", 
            eeea_run=list(eeea_params_dict.keys())),

def get_method_output(wildcards):
    return expand("results/{order}/{method}_res_{method_run}.tsv",
        order=orders, 
        method=wildcards.method, 
        method_run=list(eval(f"{wildcards.method}_params_dict").keys())
        )

rule aggregate_method:
    output:
        temp("results/_{method}_res.tsv")
    input:
        get_method_output
    run:
        import pandas as pd
        dfs = [pd.read_csv(f, sep="\t", index_col=0) for f in snakemake.input]
        df = pd.concat(dfs)
        df.to_csv(snakemake.output[0], sep="\t")

rule add_hexapoda:
    output:
        res_file="results/{method}_res.tsv"
    input:
        res="results/_{method}_res.tsv",
        hex_tax="data/Hexapoda_taxonomy.tsv",
        finbol_tax="evaluation_data/finbol_taxonomy.tsv",
        params="runs/{method}_run_params.tsv",
        se_family="evaluation_data/se_fauna_family.tsv",
    log:
        "logs/{method}/add_hexapoda.log"
    params:
        eval_fun=workflow.source_path("code/evaluate_fxns.R"),
        get_data=workflow.source_path("code/get_data_fxns.R"),
    script:
        "scripts/add_hexapoda.R"
        